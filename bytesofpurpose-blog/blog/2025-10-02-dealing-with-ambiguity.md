# How do I deal with Ambiguity
* Ambiguity usually comes from **unclear goals, evolving customer needs, or immature technology**.
* I ground things in the customer - I let customer data and behavior influence 
* I use POCs / experiments and have them influence ...
* Run an experiment asap 
* Once we have data - it will inform next steps 
* Dive deep into the experiment and iterate ...
* Do the best with what we have and evolve 
* My **two main examples** of this 
  - search customer experience - there was a problem - people were abandoning their search requests on amaozn.com for fashion products - and how to solve it was not clear - we didn't have clear goals. We ran a few experiments in this regards that taught us a lot - about how people perceive add - the impact of placing a search widget at the top / middle / bottom of a page - the impact of getting the images right on a widget, etc ...
  * Another example of this was profile of 1 ... 

Show that you don’t freeze in this space — instead you clarify what is known and start from there.

Outcome focused 

# -----------------


Great question — this is one of the core signals hiring managers want to see in senior+ roles, especially in Applied AI where requirements shift fast and the tech landscape is evolving weekly.

Here’s how you can frame navigating ambiguity & adapting to changing product needs in a way that resonates with Zapier’s principles:

1. Recognize the Ambiguity Early

Ambiguity usually comes from unclear goals, evolving customer needs, or immature technology.

Show that you don’t freeze in this space — instead you clarify what is known and start from there.

Example: “We weren’t sure whether customers wanted natural language prompts or pre-built templates, so I scoped a lightweight experiment to test both.”

2. Anchor to Outcomes, Not Solutions

Tie back to business/user value instead of just technical purity.

Ask: What problem are we solving? What metric matters here?

Example: “Rather than debate LLM architectures, we focused on reducing the time it took a user to create their first automation from 20 minutes to under 5.”

3. Use Iteration to Reduce Uncertainty

Build small, testable prototypes (aligns with Move Fast Forward).

Use metrics, customer feedback, or A/B testing to decide where to invest.

Example: “I shipped a rough prototype to 50 beta users in under 2 weeks, then pivoted based on their usage patterns.”

4. Collaborate & Re-align Constantly

Partner with PMs/design/other engineers to reframe scope as needs shift.

Communicate tradeoffs clearly: “If we go with option A, we deliver faster but risk scaling issues. If B, we’re slower but future-proof.”

Show humility and flexibility — you’re not married to a single solution.

5. Adapt Through Continuous Learning

Be explicit about lessons learned from pivots.

Example: “Initially we over-invested in fine-tuning, but customer adoption lagged. I learned to validate product-market fit before scaling model work.”

How to Frame in Interview (Sample Answer Skeleton)

“In applied AI, ambiguity is the default. One example was when we were building an LLM-powered feature, but we weren’t sure which workflow would resonate with customers. Instead of debating internally, I proposed a lightweight prototype to validate assumptions quickly.

I worked with PM to define success as improving task completion time. We launched two small variants to a pilot group, measured usage, and collected direct customer feedback. When results showed customers wanted structured templates more than free-form prompting, we pivoted.

The outcome was a production-ready feature that reduced onboarding friction by 40%. More importantly, the process taught me how to reduce risk by running small experiments early, and how to stay aligned with product even as requirements changed.”